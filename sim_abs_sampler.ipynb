{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf99ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_z = [0.5, 0.7, 1.0, 1.5, 2.0] # All redshifts for DESI MgII simulated absorbers from SALSA\n",
    "for this_z in file_z:\n",
    "    print('Processing z = ' + str(this_z) + '...')\n",
    "    file_in = 'spectra_TNG50-1_z{z}_n1000d2-fullbox_DESI_MgII_combined.hdf5'.format(z=this_z)\n",
    "    file_out = 'Tau_MgII_z{z}.hdf5'.format(z=this_z)\n",
    "    fits_out = 'MgII_Simulated_Catalog_z{z}.fits'.format(z=this_z)\n",
    "    i = 0 # Counter for absorbers\n",
    "    with h5py.File(file_in,'r') as f_in:\n",
    "        wave_array = f_in['wave'][:] # wavelegnth range same for all files, same as DESI range\n",
    "        nabs = int(1e3); cols = len(wave_array); chunk_rows = 100; chunks = (chunk_rows, cols)\n",
    "        rand_abs = np.random.permutation(int(1e6)) # Randomly shuffle the indices of the absorbers to sample randomly\n",
    "        down_chucks = np.arange(0, nabs + chunk_rows, chunk_rows)\n",
    "        ind_array = np.empty(nabs); z_avg = np.empty(nabs); EW_2796_array = np.empty(nabs) \n",
    "        EW_2803_array = np.empty(nabs); tau_data = []; N_2796_array = np.empty(nabs) \n",
    "        N_2803_array = np.empty(nabs) # initialize arrays\n",
    "        \n",
    "        for k in range(len(down_chucks) - 1): # Loop through the first 10 chunks of 1000 absorbers each, total of 10,000 absorbers per redshift\n",
    "            this_chuck = rand_abs[down_chucks[k]:down_chucks[k+1]]\n",
    "            tau_2796 = f_in['tau_MgII_2796'][this_chuck] # optical depth array of the 2796 line\n",
    "            tau_2803 = f_in['tau_MgII_2803'][this_chuck] # optical depth array of the 2803 line\n",
    "            EW_2796 = f_in['EW_MgII_2796'][this_chuck] # Equivelent width of the  2796 line\n",
    "            EW_2803 = f_in['EW_MgII_2803'][this_chuck] # Equivelent width of the  2803 line\n",
    "            N_2796 = f_in['N_MgII_2796'][this_chuck] # Column density of the 2796 line\n",
    "            N_2803 = f_in['N_MgII_2803'][this_chuck] # Column density of the 2803 line\n",
    "\n",
    "            with h5py.File(file_out, \"w\") as f:\n",
    "                f.create_dataset(\"wave\", data=wave_array) \n",
    "                dset = f.create_dataset(\n",
    "                    \"tau_MgII\",\n",
    "                    shape=(nabs, cols),\n",
    "                    dtype=np.float32,\n",
    "                    chunks=chunks,\n",
    "                    compression=\"gzip\",\n",
    "                    compression_opts=4,\n",
    "                    shuffle=True\n",
    "                )\n",
    "                \n",
    "                for j in rand_abs: # Want n absorbers\n",
    "                    if len(z_avg) >= nabs:\n",
    "                        break\n",
    "                    this_EW_2796 = EW_2796[j]\n",
    "                    if (this_EW_2796/(this_z + 1)) > 0.05: # Only consider absorbers with non-zero REW\n",
    "                        tau_2796_array = np.asarray(tau_2796[j])\n",
    "                        tau_2803_array = np.asarray(tau_2803[j])\n",
    "                        tau_tot = tau_2796_array + tau_2803_array # Total Optical Depth\n",
    "                        z_2796 = (wave_array[np.argmax(tau_2796_array)] / 2796.35) - 1 # Redshift from 2796 line\n",
    "                        z_2803 = (wave_array[np.argmax(tau_2803_array)] / 2803.53) - 1 # Redshift from 2803 line\n",
    "                        ind_array.append(j)\n",
    "                        z_avg.append((z_2796 + z_2803) / 2)\n",
    "                        EW_2796_array.append(this_EW_2796)\n",
    "                        EW_2803_array.append(EW_2803[j])\n",
    "                        N_2796_array.append(N_2796[j])\n",
    "                        N_2803_array.append(N_2803[j])        \n",
    "                        tau_data.append(tau_tot)\n",
    "                        i += 1 # Counter for absorbers\n",
    "                        if np.size(tau_data, axis=0) == chunk_rows: # Write to file in chunks of 1000 absorbers\n",
    "                            dset[len(z_avg)-chunk_rows:len(z_avg),:] = np.vstack(tau_data)\n",
    "                            tau_data.clear() # Clear the list for the next chunk\n",
    "                            print(len(z_avg))\n",
    "\n",
    "        # Create and Save Catalog and Tau Data    \n",
    "\n",
    "    t = Table()\n",
    "    t['Sim_Index'] = ind_array\n",
    "    t['Z'] = z_avg\n",
    "    t['EW_2796'] = EW_2796_array\n",
    "    t['EW_2803'] = EW_2803_array\n",
    "    t['N_2796'] = N_2796_array\n",
    "    t['N_2803'] = N_2803_array\n",
    "    t.write(fits_out, format='fits', overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
